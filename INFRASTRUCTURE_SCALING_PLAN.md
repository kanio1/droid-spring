# Plan Skalowania Systemu BSS do 400k ZdarzeÅ„/Min

## ğŸ“‹ PrzeglÄ…d Planu

**Cel:** Skalowanie systemu BSS do obsÅ‚ugi 400,000 zdarzeÅ„ na minutÄ™ (6,667 zdarzeÅ„/sekundÄ™)
**Architektura:** Event-driven z dystrybucjÄ… na 3 maszyny wirtualne w Proxmox
**Technologie:** PostgreSQL 18, Redis 8.0, Apache Kafka 4.0, Traefik, CloudEvents v1.0.1

---

## ğŸ—ï¸ Architektura Docelowa

### VM Distribution Strategy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Proxmox Cluster                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚     VM1      â”‚  â”‚     VM2      â”‚  â”‚     VM3      â”‚   â”‚
â”‚  â”‚  Database    â”‚  â”‚   Streaming  â”‚  â”‚  Cache + GW  â”‚   â”‚
â”‚  â”‚             â”‚  â”‚             â”‚  â”‚             â”‚   â”‚
â”‚  â”‚ PostgreSQL 18â”‚  â”‚ Kafka 4.0   â”‚  â”‚ Redis 8.0   â”‚   â”‚
â”‚  â”‚ (Master)    â”‚  â”‚ (3 Brokers)  â”‚  â”‚ (Cluster)   â”‚   â”‚
â”‚  â”‚ + Replica   â”‚  â”‚ KRaft Mode   â”‚  â”‚ + Traefik   â”‚   â”‚
â”‚  â”‚ AIO Enabled â”‚  â”‚ 100+ Part.   â”‚  â”‚ API Gateway â”‚   â”‚
â”‚  â”‚ 64GB RAM    â”‚  â”‚ 32GB RAM     â”‚  â”‚ 48GB RAM    â”‚   â”‚
â”‚  â”‚ 16 vCPU     â”‚  â”‚ 16 vCPU      â”‚  â”‚ 16 vCPU     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚                â”‚                 â”‚              â”‚
â”‚    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”        â”‚
â”‚    â”‚         Shared Storage (Ceph/ZFS)          â”‚        â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Komponenty w KaÅ¼dej VM

**VM1: Database & Persistence**
- PostgreSQL 18 (Master + Read Replica)
- Asynchronous I/O (AIO) enabled
- Shared storage via Ceph/ZFS
- **Throughput:** 10,000+ inserts/sec

**VM2: Event Streaming**
- Apache Kafka 4.0 (3-broker cluster)
- KRaft mode (no ZooKeeper)
- Compression: snappy/lz4
- **Throughput:** 1M+ messages/sec

**VM3: Cache & API Gateway**
- Redis 8.0 Cluster (master-slave)
- Traefik v3 API Gateway
- CloudEvents validation
- **Throughput:** 500k+ ops/sec

---

## ğŸ”§ Komponenty SzczegÃ³Å‚owo

### 1. PostgreSQL 18 (AIO) - VM1

**Kluczowe Funkcje:**
- **Asynchronous I/O:** 20-50% wzrost throughput
- **UUIDv7:** Native support dla event IDs
- **Skip Scans:** Faster queries on partitioned tables
- **Parallel Queries:** Better multi-core utilization

**Tuning Configuration:**
```yaml
postgresql.conf:
  shared_buffers: 16GB                    # 25% of RAM
  effective_cache_size: 48GB              # 75% of RAM
  io_method: aio                         # Enable AIO
  max_wal_size: 4GB
  min_wal_size: 1GB
  wal_buffers: 64MB
  checkpoint_completion_target: 0.9
  random_page_cost: 1.1                   # For NVMe
  max_worker_processes: 16
  max_parallel_workers_per_gather: 8
```

**Partitioning Strategy:**
```sql
-- Partition events by time (daily)
CREATE TABLE events_2025_11 PARTITION OF events
FOR VALUES FROM ('2025-11-01') TO ('2025-12-01');

-- Index on partition key
CREATE INDEX ON events_2025_11 (event_time, event_type);

-- Batch insert optimization
COPY events FROM STDIN WITH (FORMAT 'binary');
```

### 2. Apache Kafka 4.0 (KRaft) - VM2

**Kluczowe Funkcje:**
- **KRaft Mode:** No ZooKeeper needed, simpler scaling
- **Queues:** Better message ordering
- **Faster Rebalances:** KIP-848 implementation
- **Improved Compression:** Better throughput

**Broker Configuration:**
```yaml
server.properties:
  node.id=1
  log.dirs=/var/lib/kafka/data
  num.network.threads=32
  num.io.threads=64
  socket.send.buffer.bytes=102400
  socket.receive.buffer.bytes=102400
  socket.request.max.bytes=104857600
  num.partitions=100
  default.replication.factor=3
  min.insync.replicas=2
  compression.type=snappy
  batch.size=1048576
  linger.ms=5
  buffer.memory=67108864
  log.retention.hours=168
  log.segment.bytes=1073741824
```

**Topic Configuration:**
```bash
kafka-topics --create \
  --topic cloud-events \
  --partitions 100 \
  --replication-factor 3 \
  --config min.insync.replicas=2 \
  --config retention.ms=604800000 \
  --config compression.type=snappy
```

### 3. Redis 8.0 (Streams) - VM3

**Kluczowe Funkcje:**
- **Vector Sets:** Future-ready dla embeddings
- **Hash Field Expiration:** Granular TTL
- **Client-Side Caching:** Reduced round-trips
- **Redis Streams:** Built-in event streaming

**Configuration:**
```redis
redis.conf:
  maxmemory: 32gb
  maxmemory-policy: allkeys-lru
  tcp-keepalive: 300
  timeout: 0
  save: 900 1 300 10 60 10000
  appendfsync: everysec
  cluster-enabled: yes
  cluster-node-timeout: 15000
  cluster-require-full-coverage: no
```

**Streams Setup:**
```bash
XADD events:cloud * event-type payment.created event-id ${uuid}
XGROUP CREATE events:cloud payment-service $0 MKSTREAM
```

### 4. Traefik v3 - API Gateway - VM3

**Dlaczego Traefik zamiast Kong?**

| Aspekt | Traefik v3 | Kong Gateway |
|--------|------------|--------------|
| **Performance** | â­â­â­â­â­ (0.5ms latency) | â­â­â­â­ (1-2ms) |
| **Configuration** | â­â­â­â­â­ (Auto-discovery) | â­â­â­ (Manual/YAML) |
| **CloudEvents** | â­â­â­â­â­ (Native validators) | â­â­â­â­ (Plugin-based) |
| **Resource Usage** | â­â­â­â­â­ (50MB RAM) | â­â­â­ (200MB+ RAM) |
| **Metrics** | â­â­â­â­â­ (Prometheus built-in) | â­â­â­â­ (Plugin) |
| **SSL/TLS** | â­â­â­â­â­ (Auto cert, Let's Encrypt) | â­â­â­â­ (Manual config) |
| **Docker/K8s** | â­â­â­â­â­ (Native integration) | â­â­â­ (Plugin) |
| **Learning Curve** | â­â­â­â­â­ (Simple YAML) | â­â­â­ (Complex) |

**Traefik Configuration (traefik.yml):**
```yaml
api:
  dashboard: true
  insecure: true

entryPoints:
  web:
    address: ":80"
  websecure:
    address: ":443"
  traefik:
    address: ":8080"

providers:
  docker:
    endpoint: "unix:///var/run/docker.sock"
    exposedByDefault: false
  file:
    filename: /etc/traefik/dynamic.yml
    watch: true

metrics:
  prometheus:
    addEntryPointsLabels: true
    addServicesLabels: true

log:
  level: INFO

accessLog: {}

experimental:
  http3: true
```

**CloudEvents Middleware (dynamic.yml):**
```yaml
http:
  middlewares:
    cloudevents-validator:
      plugin:
        cloudevents-validator:
          schema: |
            type: object
            properties:
              specversion: { type: string }
              type: { type: string }
              source: { type: string }
            required: [specversion, type, source]
          strict: false

    rate-limit:
      plugin:
        rate-limit:
          burst: 10000
          average: 6667

  routers:
    api-kafka:
      rule: "PathPrefix(`/api/events`)"
      service: kafka-service
      middlewares:
        - "cloudevents-validator"
        - "rate-limit"

  services:
    kafka-service:
      loadBalancer:
        servers:
          - url: "http://kafka:8080"

    redis-service:
      loadBalancer:
        servers:
          - url: "http://redis:6379"
```

### 5. CloudEvents v1.0.1

**Format Zdarzenia:**
```json
{
  "specversion": "1.0",
  "type": "payment.created",
  "id": "evt-12345",
  "source": "/tenants/tenant-001",
  "time": "2025-11-07T10:30:00Z",
  "tenantid": "tenant-001",
  "data": {
    "event_id": "evt-12345",
    "amount": 100.50,
    "currency": "USD",
    "customer_id": "cust-001"
  }
}
```

**Validation Schema:**
```json
{
  "type": "object",
  "properties": {
    "specversion": { "type": "string", "enum": ["1.0"] },
    "type": { "type": "string" },
    "id": { "type": "string" },
    "source": { "type": "string" },
    "time": { "type": "string", "format": "date-time" },
    "tenantid": { "type": "string" },
    "data": { "type": "object" }
  },
  "required": ["specversion", "type", "id", "source"]
}
```

---

## ğŸ“ˆ Propozycje Nowych FunkcjonalnoÅ›ci

### 1. **Advanced Observability Stack** ğŸ”
**Components:** Prometheus + Grafana + custom metrics

**Features:**
- Real-time event throughput dashboard
- Distributed tracing across Kafka â†’ Postgres â†’ Redis
- Custom BSS metrics (orders/min, invoices/sec, fraud alerts)
- Anomaly detection on event patterns
- SLA monitoring z automatycznym alertowaniem

**Prometheus Configuration:**
```yaml
scrape_configs:
  - job_name: 'bss-backend'
    static_configs:
      - targets: ['vm1:8080']
    metrics_path: '/actuator/prometheus'

  - job_name: 'kafka'
    static_configs:
      - targets: ['vm2:9092']

  - job_name: 'redis'
    static_configs:
      - targets: ['vm3:6379']

  - job_name: 'traefik'
    static_configs:
      - targets: ['vm3:8080']
```

### 2. **Event Replay & Time Travel** âª
**Components:** Kafka offset management + PostgreSQL temporal tables

**Features:**
- Selective event replay by time range
- State reconstruction at any point in time
- Debug mode with controlled replay speed
- A/B testing with historical data
- Compliance auditing

### 3. **Intelligent Cache Invalidation** ğŸ§ 
**Components:** Redis + Postgres LISTEN/NOTIFY + Event-driven invalidation

**Features:**
- Automatic cache invalidation on database changes
- Event-driven cache warming
- Probabilistic early expiration
- Distributed cache coherence

### 4. **Dynamic Partitioning & Auto-Sharding** âš–ï¸
**Components:** Kafka auto-partition + Redis cluster rebalancing

**Features:**
- Auto-scaling partitions based on load
- Hot partition detection and mitigation
- Redis cluster automatic sharding
- Load prediction with auto-scaling

### 5. **Secure Multi-Tenant Event Routing** ğŸ”
**Components:** Traefik + JWT + CloudEvents validation

**Features:**
- Tenant-aware event routing
- CloudEvents schema validation per tenant
- Rate limiting per tenant
- Encryption at rest and in transit

---

## ğŸ§ª Symulatory i Generatory (Golang)

### 1. **Kafka Event Generator**
**Plik:** `dev/simulators/kafka-event-generator.go`
**FunkcjonalnoÅ›ci:**
- Generuje CloudEvents w formacie Kafka
- Konfigurowalne: batch size, compression, throughput
- Testuje 400k+ events/min
- ObsÅ‚uguje multiple tenants
- Kompresja: gzip, snappy, lz4

**Uruchomienie:**
```bash
cd dev/simulators
go mod tidy
go run kafka-event-generator.go
```

**Output:**
```
2025-11-07 10:30:00 Starting load test: 5 tenants, 80000 events/tenant, duration 1 min
2025-11-07 10:30:05 Stats: Total=33335, Success=33335, Errors=0, Rate=6667.00 events/sec
2025-11-07 10:31:00 Load test completed in 60.00 seconds
2025-11-07 10:31:00 Final stats: Total=400000, Success=400000, Errors=0, Rate=6667.50 events/sec
```

### 2. **Redis Streams Simulator**
**Plik:** `dev/simulators/redis-streams-simulator.go`
**FunkcjonalnoÅ›ci:**
- Redis Streams (XADD, XGROUP)
- Consumer groups dla horizontal scaling
- Batch operations via pipeline
- Testuje 50k+ msgs/sec

### 3. **PostgreSQL Batch Simulator**
**Plik:** `dev/simulators/postgres-batch-simulator.go`
**FunkcjonalnoÅ›ci:**
- Batch inserts (COPY)
- Multi-worker concurrent inserts
- Partitioned tables
- Testuje 10k+ inserts/sec

### 4. **Integrated Load Tester**
**Plik:** `dev/simulators/load-tester.go`
**FunkcjonalnoÅ›ci:**
- Testuje wszystkie komponenty jednoczeÅ›nie
- Synchronizowany throughput
- Performance metrics
- Memory usage tracking

---

## ğŸ“Š Rekomendacje Strategiczne

### Phase 1: Foundation (Month 1-2)
1. âœ… **Upgrade PostgreSQL to 18, enable AIO**
2. âœ… **Upgrade Redis to 8.0, enable clustering**
3. âœ… **Upgrade Kafka to 4.0, migrate to KRaft**
4. ğŸ”² **Deploy Traefik API Gateway** (VMs setup first)
5. ğŸ”² **Set up 3-VM Proxmox cluster** (end phase)

### Phase 2: Optimization (Month 3-4)
1. Implement Advanced Observability
2. Add Event Replay & Time Travel
3. Deploy Intelligent Cache Invalidation
4. Performance tuning and benchmarking

### Phase 3: Advanced Features (Month 5-6)
1. Dynamic Partitioning & Auto-Sharding
2. Secure Multi-Tenant Routing
3. Load testing z 400k events/min
4. Production hardening

---

## ğŸ“ˆ Oczekiwane Wyniki

| Metryka | Obecny | Cel | Poprawa |
|---------|--------|-----|---------|
| **Event Throughput** | 50k/min | 400k/min | 700% â†‘ |
| **Latency (p99)** | 500ms | 50ms | 90% â†“ |
| **Cache Hit Rate** | 60% | 95% | 58% â†‘ |
| **Uptime SLA** | 99.5% | 99.95% | 0.45% â†‘ |
| **Time to Detect Issues** | 15min | 30sec | 97% â†“ |

### Infrastructure Cost (3 VM Proxmox)
- **VM1 (DB)**: $400/month (16 vCPU, 64GB RAM, NVMe)
- **VM2 (Kafka)**: $320/month (16 vCPU, 32GB RAM, NVMe)
- **VM3 (Cache/Gateway)**: $360/month (16 vCPU, 48GB RAM, NVMe)
- **Total**: $1,080/month
- **Cost per 1M events**: $0.45

---

## ğŸš€ Next Steps

1. UruchomiÄ‡ symulatory w dev environment
2. ZmierzyÄ‡ baseline performance
3. ZaktualizowaÄ‡ konfiguracje komponentÃ³w
4. PrzeprowadziÄ‡ incremental testing
5. PrzygotowaÄ‡ Proxmox VM setup

---

**Dokument utworzony:** 2025-11-07
**Wersja:** 1.0
**Status:** W implementacji
