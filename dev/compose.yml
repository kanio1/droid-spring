version: "3.9"

x-common-env: &common-environment
  SPRING_PROFILES_ACTIVE: dev

services:
  postgres:
    image: postgres:18-alpine
    container_name: bss-postgres
    restart: unless-stopped
    env_file:
      - ../.env
    environment:
      POSTGRES_HOST_AUTH_METHOD: scram-sha-256
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./certs/postgres:/etc/ssl/certs:ro
      - ./certs/ca:/etc/ssl/ca:ro
      - ./postgres/postgresql-ssl.conf:/etc/postgresql/postgresql.conf:ro
    command: postgres -c config_file=/etc/postgresql/postgresql.conf
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  redis:
    image: redis:8.0-alpine
    container_name: bss-redis
    restart: unless-stopped
    command: redis-server /usr/local/etc/redis/redis.conf
    ports:
      - "6379:6379"
    volumes:
      - ./redis/redis.conf:/usr/local/etc/redis/redis.conf:ro
      - ./certs/redis:/etc/ssl/certs:ro
      - ./certs/redis:/etc/ssl/private:ro
      - ./certs/ca:/etc/ssl/ca:ro
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "--tls", "--cacert", "/etc/ssl/ca/ca-cert.pem", "-a", "${REDIS_PASSWORD:-redis_password_123}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  keycloak:
    image: quay.io/keycloak/keycloak:26.0
    container_name: bss-keycloak
    restart: unless-stopped
    command:
      - start-dev
      - --import-realm
      - --http-enabled=true
      - --health-enabled=true
      - --cache-config-file=/opt/keycloak/conf/keycloak-cache-ispn.xml
    env_file:
      - ../.env
    environment:
      KEYCLOAK_IMPORT: /opt/keycloak/data/import/realm-bss.json
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_SESSION_DB: 1
      # Cache configuration
      CACHE_OWNERS_COUNT: "1"
      CACHE_OWNERS_AUTH_SESSIONS_COUNT: "1"
      CACHE_OWNERS_ACCOUNT_SESSIONS_COUNT: "1"
    volumes:
      - ../infra/keycloak:/opt/keycloak/data/import:ro
      - ../infra/keycloak/conf/keycloak-cache-ispn.xml:/opt/keycloak/conf/keycloak-cache-ispn.xml:ro
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    ports:
      - "8081:8080"
    healthcheck:
      test:
        - CMD-SHELL
        - exec 3<>/dev/tcp/127.0.0.1/9000 && printf "GET /health/ready HTTP/1.0\r\n\r\n" >&3 && read -r line <&3 && exec 3>&- && case "$$line" in *200*) exit 0 ;; *) exit 1 ;; esac
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 20s
    networks:
      - bss-net

  backend:
    build:
      context: ../backend
      dockerfile: Dockerfile
    container_name: bss-backend
    restart: unless-stopped
    env_file:
      - ../.env
    environment:
      <<: *common-environment
      SPRING_REDIS_HOST: redis
      # TLS Configuration
      SERVER_SSL_ENABLED: "true"
      SERVER_SSL_KEY_STORE: /etc/ssl/certs/backend-cert.p12
      SERVER_SSL_KEY_STORE_PASSWORD: "changeit"
      SERVER_SSL_KEY_STORE_TYPE: PKCS12
      SERVER_SSL_TRUST_STORE: /etc/ssl/certs/truststore.jks
      SERVER_SSL_TRUST_STORE_PASSWORD: "changeit"
      SERVER_SSL_CLIENT_AUTH_ENABLED: "true"
      SERVER_SSL_ENABLED_PROTOCOLS: TLSv1.2,TLSv1.3
      SERVER_SSL_CIPHERS: TLS_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
      # Kafka SSL Configuration
      KAFKA_SSL_ENABLED: "true"
      KAFKA_SSL_KEYSTORE_PASSWORD: "changeit"
      KAFKA_SSL_TRUSTSTORE_PASSWORD: "changeit"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      keycloak:
        condition: service_healthy
    ports:
      - "8080:8080"   # HTTP
      - "8443:8443"   # HTTPS/mTLS
    volumes:
      - ./certs/server:/etc/ssl/certs:ro
      - ./certs/ca:/etc/ssl/ca:ro
      - ./certs/kafka:/etc/ssl/certs/kafka:ro
    labels:
      - "traefik.enable=true"
      # Backend API - All routes
      - "traefik.http.routers.backend-api.rule=Host(`api.bss.local`) && PathPrefix(`/api`)"
      - "traefik.http.routers.backend-api.entrypoints=websecure"
      - "traefik.http.routers.backend-api.tls.certresolver=letsencrypt"
      - "traefik.http.routers.backend-api.service=backend"
      - "traefik.http.services.backend.loadbalancer.server.port=8080"
      - "traefik.http.routers.backend-api.middlewares=cors-header,security-headers,rate-limit-standard"
      # Health check endpoint
      - "traefik.http.routers.health.rule=Host(`api.bss.local`) && Path(`/health`)"
      - "traefik.http.routers.health.entrypoints=websecure"
      - "traefik.http.routers.health.tls.certresolver=letsencrypt"
      - "traefik.http.routers.health.service=backend"
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:8080/actuator/health | grep UP"]
      interval: 15s
      timeout: 5s
      retries: 10
      start_period: 30s
    networks:
      - bss-net

  frontend:
    build:
      context: ../frontend
      dockerfile: Dockerfile
    container_name: bss-frontend
    restart: unless-stopped
    env_file:
      - ../.env
    environment:
      NUXT_PUBLIC_API_BASE_URL: http://backend:8080
      NUXT_PUBLIC_KEYCLOAK_URL: http://keycloak:8080
      NUXT_PUBLIC_KEYCLOAK_REALM: bss
      NUXT_PUBLIC_KEYCLOAK_CLIENT_ID: ${KEYCLOAK_FRONTEND_CLIENT_ID}
    depends_on:
      backend:
        condition: service_healthy
    ports:
      - "3000:3000"
    labels:
      - "traefik.enable=true"
      # Frontend
      - "traefik.http.routers.frontend.rule=Host(`bss.local`) || Host(`www.bss.local`)"
      - "traefik.http.routers.frontend.entrypoints=websecure"
      - "traefik.http.routers.frontend.tls.certresolver=letsencrypt"
      - "traefik.http.routers.frontend.service=frontend"
      - "traefik.http.services.frontend.loadbalancer.server.port=3000"
      - "traefik.http.routers.frontend.middlewares=security-headers"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/"]
      interval: 15s
      timeout: 5s
      retries: 10
      start_period: 30s
    networks:
      - bss-net

  # ================================
  # Observability Stack - Tempo (Traces)
  # ================================
  tempo:
    image: grafana/tempo:2.6.1
    container_name: bss-tempo
    restart: unless-stopped
    command: -config.file=/etc/tempo.yaml
    ports:
      - "3200:3200"   # Tempo HTTP
      - "4317:4317"   # OTLP gRPC
      - "4318:4318"   # OTLP HTTP
    volumes:
      - ./tempo/tempo.yaml:/etc/tempo.yaml:ro
      - tempo-data:/var/lib/tempo
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3200/ready"]
      interval: 15s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # Observability Stack - Loki (Logs)
  # ================================
  loki:
    image: grafana/loki:3.3.0
    container_name: bss-loki
    restart: unless-stopped
    command: -config.file=/etc/loki/local-config.yaml
    ports:
      - "3100:3100"
    volumes:
      - ./loki/loki-config.yaml:/etc/loki/local-config.yaml:ro
      - loki-data:/var/loki
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3100/ready"]
      interval: 15s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # Observability Stack - Promtail (Log Collector)
  # ================================
  promtail:
    image: grafana/promtail:3.3.0
    container_name: bss-promtail
    restart: unless-stopped
    command: -config.file=/etc/promtail/config.yml
    volumes:
      - ./promtail/promtail-config.yml:/etc/promtail/config.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      - loki
    networks:
      - bss-net

  # ================================
  # Observability Stack - Grafana (Dashboards)
  # ================================
  grafana:
    image: grafana/grafana:11.2.0
    container_name: bss-grafana
    restart: unless-stopped
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_AUTH_ANONYMOUS_ENABLED=false
      - GF_SECURITY_DISABLE_GRAVATAR=true
      - GF_ANALYTICS_REPORTING_ENABLED=false
      - GF_ANALYTICS_CHECK_FOR_UPDATES=false
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
    depends_on:
      - prometheus
      - tempo
      - loki
    ports:
      - "3001:3000"
    labels:
      - "traefik.enable=true"
      # Grafana
      - "traefik.http.routers.grafana.rule=Host(`grafana.bss.local`)"
      - "traefik.http.routers.grafana.entrypoints=websecure"
      - "traefik.http.routers.grafana.tls.certresolver=letsencrypt"
      - "traefik.http.routers.grafana.service=grafana"
      - "traefik.http.services.grafana.loadbalancer.server.port=3000"
      - "traefik.http.routers.grafana.middlewares=security-headers"
      - "traefik.http.middlewares.grafana-redirect.redirectregex.regex=^https://grafana.bss.local/$$"
      - "traefik.http.middlewares.grafana-redirect.redirectregex.replacement=https://grafana.bss.local/d"
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000/api/health || exit 1"]
      interval: 15s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # Observability Stack - Prometheus (Metrics)
  # ================================
  prometheus:
    image: prom/prometheus:v2.55.1
    container_name: bss-prometheus
    restart: unless-stopped
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    ports:
      - "9090:9090"
    labels:
      - "traefik.enable=true"
      # Prometheus
      - "traefik.http.routers.prometheus.rule=Host(`prometheus.bss.local`)"
      - "traefik.http.routers.prometheus.entrypoints=websecure"
      - "traefik.http.routers.prometheus.tls.certresolver=letsencrypt"
      - "traefik.http.routers.prometheus.service=prometheus"
      - "traefik.http.services.prometheus.loadbalancer.server.port=9090"
      - "traefik.http.routers.prometheus.middlewares=security-headers"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 15s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # Observability Stack - Jaeger (Distributed Tracing)
  # ================================
  jaeger:
    image: jaegertracing/all-in-one:1.62
    container_name: bss-jaeger
    restart: unless-stopped
    environment:
      - COLLECTOR_OTLP_ENABLED=true
      - SPAN_STORAGE_TYPE=elasticsearch
      - ES_SERVER_URLS=http://elasticsearch:9200
      - ES_NUM_SHARDS=1
      - ES_NUM_REPLICAS=0
    depends_on:
      - elasticsearch
    ports:
      - "16686:16686"  # Jaeger UI
      - "14268:14268"  # HTTP collector
      - "14250:14250"  # gRPC collector
    labels:
      - "traefik.enable=true"
      # Jaeger
      - "traefik.http.routers.jaeger.rule=Host(`jaeger.bss.local`)"
      - "traefik.http.routers.jaeger.entrypoints=websecure"
      - "traefik.http.routers.jaeger.tls.certresolver=letsencrypt"
      - "traefik.http.routers.jaeger.service=jaeger"
      - "traefik.http.services.jaeger.loadbalancer.server.port=16686"
      - "traefik.http.routers.jaeger.middlewares=security-headers"
    networks:
      - bss-net

  # ================================
  # Elasticsearch (for Jaeger)
  # ================================
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.14.0
    container_name: bss-elasticsearch
    restart: unless-stopped
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9200/_cluster/health"]
      interval: 15s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # PgBouncer (PostgreSQL Connection Pooling)
  # ================================
  pgbouncer:
    image: pgbouncer/pgbouncer:1.25.0
    container_name: bss-pgbouncer
    restart: unless-stopped
    env_file:
      - ../.env
    environment:
      - DATABASES_HOST=postgres
      - DATABASES_PORT=5432
      - DATABASES_USER=${POSTGRES_USER}
      - DATABASES_PASSWORD=${POSTGRES_PASSWORD}
      - DATABASES_DBNAME=${POSTGRES_DB}
      - POOL_MODE=transaction
      - MAX_CLIENT_CONN=100
      - DEFAULT_POOL_SIZE=20
      - MIN_POOL_SIZE=5
      - RESERVE_POOL_SIZE=5
      - SERVER_LIFETIME=3600
      - SERVER_IDLE_TIMEOUT=600
      - LOG_CONNECTIONS=1
      - LOG_POOLER_ERRORS=1
    ports:
      - "6432:5432"
    depends_on:
      postgres:
        condition: service_healthy
    volumes:
      - ./pgbouncer/pgbouncer.ini:/etc/pgbouncer/pgbouncer.ini:ro
      - ./pgbouncer/userlist.txt:/etc/pgbouncer/userlist.txt:ro
    healthcheck:
      test: ["CMD", "psql", "-h", "localhost", "-p", "5432", "-U", "${POSTGRES_USER}", "-d", "${POSTGRES_DB}", "-c", "SELECT 1"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # PgHero (Query Analysis & Performance)
  # ================================
  pghero:
    image: ankane/pghero:v3.4.0
    container_name: bss-pghero
    restart: unless-stopped
    env_file:
      - ../.env
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      - SECRET_KEY_BASE=${PGHERO_SECRET_KEY_BASE:-secret_key_base_change_in_production}
    ports:
      - "8082:3000"
    depends_on:
      postgres:
        condition: service_healthy
    labels:
      - "traefik.enable=true"
      # PgHero
      - "traefik.http.routers.pghero.rule=Host(`pghero.bss.local`)"
      - "traefik.http.routers.pghero.entrypoints=websecure"
      - "traefik.http.routers.pghero.tls.certresolver=letsencrypt"
      - "traefik.http.routers.pghero.service=pghero"
      - "traefik.http.services.pghero.loadbalancer.server.port=3000"
      - "traefik.http.routers.pghero.middlewares=security-headers"
    networks:
      - bss-net

  # ================================
  # PHASE 2: CORE INFRASTRUCTURE
  # ================================

  # ================================
  # Kafka Brokers (Cluster) - KRaft Mode (Kafka 4.0)
  # ================================
  kafka-1:
    image: apache/kafka:4.0.0
    container_name: bss-kafka-1
    restart: unless-stopped
    environment:
      KAFKA_NODE_ID: 1
      # SSL Listeners
      KAFKA_LISTENERS: SSL://kafka-1:9092,SSL_HOST://localhost:9092
      KAFKA_ADVERTISED_LISTENERS: SSL://kafka-1:9092,SSL_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: SSL:SSL,SSL_HOST:SSL
      KAFKA_INTER_BROKER_LISTENER_NAME: SSL
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka-1:9093,2@kafka-2:9093,3@kafka-3:9093
      KAFKA_LISTENERS: CONTROLLER://kafka-1:9093,SSL://kafka-1:9092,SSL_HOST://localhost:9092
      KAFKA_ADVERTISED_LISTENERS: SSL://kafka-1:9092,SSL_HOST://localhost:9092
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LOG_DIRS: /tmp/kraft-combined-logs
      # SSL Configuration
      KAFKA_SSL_KEYSTORE_LOCATION: /etc/ssl/certs/kafka.p12
      KAFKA_SSL_KEYSTORE_PASSWORD: changeit
      KAFKA_SSL_KEYSTORE_TYPE: PKCS12
      KAFKA_SSL_TRUSTSTORE_LOCATION: /etc/ssl/certs/truststore.jks
      KAFKA_SSL_TRUSTSTORE_PASSWORD: changeit
      KAFKA_SSL_CLIENT_AUTH: required
      KAFKA_SSL_ENABLED_PROTOCOLS: TLSv1.2,TLSv1.3
      KAFKA_SSL_CIPHER_SUITES: TLS_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
      KAFKA_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: HTTPS
      KAFKA_NUM_PARTITIONS: 100
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_RETENTION_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_COMPRESSION_TYPE: snappy
      KAFKA_BATCH_SIZE: 1048576
      KAFKA_LINGER_MS: 5
      KAFKA_BUFFER_MEMORY: 67108864
      KAFKA_NUM_NETWORK_THREADS: 32
      KAFKA_NUM_IO_THREADS: 64
      KAFKA_SOCKET_SEND_BUFFER_BYTES: 102400
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 102400
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600
      KAFKA_JVM_PERFORMANCE_OPTS: -Xms1g -Xmx1g
    volumes:
      - ./certs/kafka:/etc/ssl/certs:ro
      - ./certs/ca:/etc/ssl/ca:ro
      - kafka-1-data:/tmp/kraft-combined-logs
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:9092 --list --command-config /etc/ssl/certs/kafka-client.properties"]
      interval: 15s
      timeout: 10s
      retries: 5
    networks:
      - bss-net

  kafka-2:
    image: apache/kafka:4.0.0
    container_name: bss-kafka-2
    restart: unless-stopped
    environment:
      KAFKA_NODE_ID: 2
      # SSL Listeners
      KAFKA_LISTENERS: SSL://kafka-2:9092,SSL_HOST://localhost:9093
      KAFKA_ADVERTISED_LISTENERS: SSL://kafka-2:9092,SSL_HOST://localhost:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: SSL:SSL,SSL_HOST:SSL
      KAFKA_INTER_BROKER_LISTENER_NAME: SSL
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka-1:9093,2@kafka-2:9093,3@kafka-3:9093
      KAFKA_LISTENERS: CONTROLLER://kafka-2:9093,SSL://kafka-2:9092,SSL_HOST://localhost:9093
      KAFKA_ADVERTISED_LISTENERS: SSL://kafka-2:9092,SSL_HOST://localhost:9093
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LOG_DIRS: /tmp/kraft-combined-logs
      # SSL Configuration
      KAFKA_SSL_KEYSTORE_LOCATION: /etc/ssl/certs/kafka.p12
      KAFKA_SSL_KEYSTORE_PASSWORD: changeit
      KAFKA_SSL_KEYSTORE_TYPE: PKCS12
      KAFKA_SSL_TRUSTSTORE_LOCATION: /etc/ssl/certs/truststore.jks
      KAFKA_SSL_TRUSTSTORE_PASSWORD: changeit
      KAFKA_SSL_CLIENT_AUTH: required
      KAFKA_SSL_ENABLED_PROTOCOLS: TLSv1.2,TLSv1.3
      KAFKA_SSL_CIPHER_SUITES: TLS_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
      KAFKA_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: HTTPS
      KAFKA_NUM_PARTITIONS: 100
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_RETENTION_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_COMPRESSION_TYPE: snappy
      KAFKA_BATCH_SIZE: 1048576
      KAFKA_LINGER_MS: 5
      KAFKA_BUFFER_MEMORY: 67108864
      KAFKA_NUM_NETWORK_THREADS: 32
      KAFKA_NUM_IO_THREADS: 64
      KAFKA_SOCKET_SEND_BUFFER_BYTES: 102400
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 102400
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600
      KAFKA_JVM_PERFORMANCE_OPTS: -Xms1g -Xmx1g
    volumes:
      - ./certs/kafka:/etc/ssl/certs:ro
      - ./certs/ca:/etc/ssl/ca:ro
      - kafka-2-data:/tmp/kraft-combined-logs
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:9093 --list --command-config /etc/ssl/certs/kafka-client.properties"]
      interval: 15s
      timeout: 10s
      retries: 5
    networks:
      - bss-net

  kafka-3:
    image: apache/kafka:4.0.0
    container_name: bss-kafka-3
    restart: unless-stopped
    environment:
      KAFKA_NODE_ID: 3
      # SSL Listeners
      KAFKA_LISTENERS: SSL://kafka-3:9092,SSL_HOST://localhost:9094
      KAFKA_ADVERTISED_LISTENERS: SSL://kafka-3:9092,SSL_HOST://localhost:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: SSL:SSL,SSL_HOST:SSL
      KAFKA_INTER_BROKER_LISTENER_NAME: SSL
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka-1:9093,2@kafka-2:9093,3@kafka-3:9093
      KAFKA_LISTENERS: CONTROLLER://kafka-3:9093,SSL://kafka-3:9092,SSL_HOST://localhost:9094
      KAFKA_ADVERTISED_LISTENERS: SSL://kafka-3:9092,SSL_HOST://localhost:9094
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LOG_DIRS: /tmp/kraft-combined-logs
      # SSL Configuration
      KAFKA_SSL_KEYSTORE_LOCATION: /etc/ssl/certs/kafka.p12
      KAFKA_SSL_KEYSTORE_PASSWORD: changeit
      KAFKA_SSL_KEYSTORE_TYPE: PKCS12
      KAFKA_SSL_TRUSTSTORE_LOCATION: /etc/ssl/certs/truststore.jks
      KAFKA_SSL_TRUSTSTORE_PASSWORD: changeit
      KAFKA_SSL_CLIENT_AUTH: required
      KAFKA_SSL_ENABLED_PROTOCOLS: TLSv1.2,TLSv1.3
      KAFKA_SSL_CIPHER_SUITES: TLS_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
      KAFKA_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: HTTPS
      KAFKA_NUM_PARTITIONS: 100
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_RETENTION_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_COMPRESSION_TYPE: snappy
      KAFKA_BATCH_SIZE: 1048576
      KAFKA_LINGER_MS: 5
      KAFKA_BUFFER_MEMORY: 67108864
      KAFKA_NUM_NETWORK_THREADS: 32
      KAFKA_NUM_IO_THREADS: 64
      KAFKA_SOCKET_SEND_BUFFER_BYTES: 102400
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 102400
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600
      KAFKA_JVM_PERFORMANCE_OPTS: -Xms1g -Xmx1g
    volumes:
      - ./certs/kafka:/etc/ssl/certs:ro
      - ./certs/ca:/etc/ssl/ca:ro
      - kafka-3-data:/tmp/kraft-combined-logs
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:9094 --list --command-config /etc/ssl/certs/kafka-client.properties"]
      interval: 15s
      timeout: 10s
      retries: 5
    networks:
      - bss-net

  # ================================
  # Kafka Exporter (Metrics & Lag Monitoring)
  # ================================
  kafka-exporter:
    image: danielqsj/kafka-exporter:v1.9.0
    container_name: bss-kafka-exporter
    restart: unless-stopped
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
    environment:
      KAFKA_SERVERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
      KAFKA_METRICS_PATH: /metrics
      KAFKA_CLIENT_CONFIG: /etc/kafka/kafka-client.properties
    ports:
      - "9308:9308"
    volumes:
      - ./certs:/etc/kafka:ro
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9308/metrics"]
      interval: 15s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # Confluent Schema Registry
  # ================================
  schema-registry:
    image: confluentinc/cp-schema-registry:7.6.0
    container_name: bss-schema-registry
    restart: unless-stopped
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: SSL://kafka-1:9092,SSL://kafka-2:9092,SSL://kafka-3:9092
      SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: SSL
      SCHEMA_REGISTRY_KAFKASTORE_SSL_TRUSTSTORE_LOCATION: /etc/ssl/certs/truststore.jks
      SCHEMA_REGISTRY_KAFKASTORE_SSL_TRUSTSTORE_PASSWORD: changeit
      SCHEMA_REGISTRY_KAFKASTORE_SSL_KEYSTORE_LOCATION: /etc/ssl/certs/kafka.p12
      SCHEMA_REGISTRY_KAFKASTORE_SSL_KEYSTORE_PASSWORD: changeit
      SCHEMA_REGISTRY_KAFKASTORE_SSL_KEYSTORE_TYPE: PKCS12
      SCHEMA_REGISTRY_KAFKASTORE_SSL_CLIENT_AUTH: required
      SCHEMA_REGISTRY_KAFKASTORE_SSL_ENABLED_PROTOCOLS: TLSv1.2,TLSv1.3
      SCHEMA_REGISTRY_KAFKASTORE_SSL_CIPHER_SUITES: TLS_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8084
      SCHEMA_REGISTRY_INTER_INSTANCE_PROTOCOL: http
      SCHEMA_REGISTRY_ACCESS_CONTROL_ALLOW_ORIGIN: '*'
      SCHEMA_REGISTRY_ACCESS_CONTROL_ALLOW_METHODS: GET,POST,PUT,DELETE,OPTIONS
      SCHEMA_REGISTRY_MASTER_ELIGIBILITY: "true"
      SCHEMA_REGISTRY_METRICS_JMX_OPTS: -Dcom.sun.jmx.rmiport=8085
      SCHEMA_REGISTRY_DEBUG: "false"
      SCHEMA_REGISTRY_OPTS: -Xms256m -Xmx512m
    ports:
      - "8084:8084"  # Schema Registry API
      - "8085:8085"  # JMX metrics
    volumes:
      - ./certs/kafka:/etc/ssl/certs:ro
      - ./certs/ca:/etc/ssl/ca:ro
      - schema-registry-data:/var/lib/schema-registry
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8084/health"]
      interval: 15s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # Redis Cluster (Enhanced)
  # ================================
  redis-cluster:
    image: redis:8.0-alpine
    container_name: bss-redis-cluster
    restart: unless-stopped
    command: >
      redis-server
      --cluster-enabled yes
      --cluster-config-file nodes.conf
      --cluster-node-timeout 5000
      --appendonly yes
      --save 20 1
      --loglevel warning
      --tls-port 7000
      --tls-cert-file /etc/ssl/certs/redis-cert.pem
      --tls-key-file /etc/ssl/private/redis-key.pem
      --tls-ca-cert-file /etc/ssl/ca/ca-cert.pem
    ports:
      - "7000:7000"  # TLS Cluster port
      - "7001:7001"  # TLS Cluster bus port
    volumes:
      - ./certs/redis:/etc/ssl/certs:ro
      - ./certs/redis:/etc/ssl/private:ro
      - ./certs/ca:/etc/ssl/ca:ro
      - redis-cluster-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "--tls", "--cacert", "/etc/ssl/ca/ca-cert.pem", "-a", "${REDIS_PASSWORD:-redis_password_123}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # AKHQ (Kafka UI & Monitoring)
  # ================================
  akhq:
    image: tchiotludo/akhq:0.24.0
    container_name: bss-akhq
    restart: unless-stopped
    environment:
      AKHQ_CONFIGURATION: |
        akhq:
          connections:
            docker-kafka-server:
              properties:
                bootstrap.servers: kafka-1:9092,kafka-2:9092,kafka-3:9092
                security.protocol: SSL
                ssl.truststore.location: /etc/ssl/certs/truststore.jks
                ssl.truststore.password: changeit
                ssl.keystore.location: /etc/ssl/certs/kafka.p12
                ssl.keystore.password: changeit
                ssl.keystore.type: PKCS12
      AKHQ_OPTS: -Xms256m -Xmx512m
    ports:
      - "8083:8080"
    volumes:
      - ./certs:/etc/ssl/certs:ro
      - ./certs/ca:/etc/ssl/ca:ro
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
    labels:
      - "traefik.enable=true"
      # AKHQ
      - "traefik.http.routers.akhq.rule=Host(`akhq.bss.local`)"
      - "traefik.http.routers.akhq.entrypoints=websecure"
      - "traefik.http.routers.akhq.tls.certresolver=letsencrypt"
      - "traefik.http.routers.akhq.service=akhq"
      - "traefik.http.services.akhq.loadbalancer.server.port=8080"
      - "traefik.http.routers.akhq.middlewares=security-headers"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/health"]
      interval: 15s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # RedisInsight (Redis GUI)
  # ================================
  redisinsight:
    image: redislabs/redisinsight:latest
    container_name: bss-redisinsight
    restart: unless-stopped
    ports:
      - "8001:8001"
    volumes:
      - redisinsight-data:/db
      - ./certs/ca:/etc/ssl/certs/ca:ro
    environment:
      - RITRUSTEDORIGINS=http://localhost:8001
      - RITRUSTSTORE=/etc/ssl/certs/ca/ca-cert.pem
    networks:
      - bss-net
    depends_on:
      redis:
        condition: service_healthy
      redis-cluster:
        condition: service_healthy

  # ================================
  # ================================
  # Traefik API Gateway
  # ================================
  traefik:
    image: traefik:v3.0
    container_name: bss-traefik
    restart: unless-stopped
    command:
      - --configFile=/etc/traefik/traefik.yml
    ports:
      - "8000:8000"   # HTTP (redirected to HTTPS)
      - "8443:8443"   # HTTPS
      - "8080:8080"   # Traefik Dashboard
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./traefik/traefik.yml:/etc/traefik/traefik.yml:ro
      - ./traefik/dynamic.yml:/etc/traefik/dynamic.yml:ro
      - traefik-data:/etc/traefik/acme
    labels:
      - "traefik.enable=true"
      # Dashboard
      - "traefik.http.routers.traefik.rule=Host(`traefik.bss.local`)"
      - "traefik.http.routers.traefik.entrypoints=websecure"
      - "traefik.http.routers.traefik.tls.certresolver=letsencrypt"
      - "traefik.http.routers.traefik.service=api@internal"
      - "traefik.http.routers.traefik.middlewares=auth"
    environment:
      - TZ=UTC
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # PHASE 3: NETWORK & PROCESSING
  # ================================

  # ================================
  # Service Mesh - Envoy Proxy
  # ================================
  envoy:
    image: envoyproxy/envoy:v1.29.0
    container_name: bss-envoy
    restart: unless-stopped
    volumes:
      - ./envoy/envoy.yaml:/etc/envoy/envoy.yaml:ro
    ports:
      - "15001:15001"  # Admin port
      - "15006:15006"  # Proxy port
    command: ["-c", "/etc/envoy/envoy.yaml", "-l", "info"]
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:15000/ready"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # Kafka Streams - Customer Analytics
  # ================================
  kafka-streams-customer-analytics:
    image: confluentinc/cp-kafka:7.6.0
    container_name: bss-kafka-streams-customer
    restart: unless-stopped
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
    environment:
      BOOTSTRAP_SERVERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
      APPLICATION_ID: bss-customer-analytics
      INPUT_TOPIC: bss.customer.events
      OUTPUT_TOPIC: bss.analytics.events
    volumes:
      - ./kafka-streams/customer-analytics:/scripts
    command: ["sh", "/scripts/run.sh"]
    healthcheck:
      test: ["CMD", "pgrep", "-f", "kafka-console-consumer"]
      interval: 15s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # Kafka Streams - Order Processing
  # ================================
  kafka-streams-order-processor:
    image: confluentinc/cp-kafka:7.6.0
    container_name: bss-kafka-streams-order
    restart: unless-stopped
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
    environment:
      BOOTSTRAP_SERVERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
      APPLICATION_ID: bss-order-processor
      INPUT_TOPIC: bss.order.events
      OUTPUT_TOPIC: bss.analytics.events
    volumes:
      - ./kafka-streams/order-processor:/scripts
    command: ["sh", "/scripts/run.sh"]
    healthcheck:
      test: ["CMD", "pgrep", "-f", "kafka-console-consumer"]
      interval: 15s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # PostgreSQL Read Replica 1
  # ================================
  postgres-replica-1:
    image: postgres:18-alpine
    container_name: bss-postgres-replica-1
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_MASTER_SERVICE: bss-postgres
      POSTGRES_REPLICA_MODE: slave
    ports:
      - "5433:5432"
    volumes:
      - postgres-replica-1-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - bss-net
    command: >
      bash -c "
      echo 'Checking if primary is ready...'
      until pg_isready -h bss-postgres -p 5432; do
        sleep 2
      done
      echo 'Primary is ready, starting replica...'
      rm -f /var/lib/postgresql/data/postmaster.pid
      su - postgres -c 'pg_basebackup -h bss-postgres -p 5432 -D /var/lib/postgresql/data -U replication -v -P -R'
      echo 'standby_mode = on' > /var/lib/postgresql/data/postgresql.conf
      echo 'primary_conninfo = ''host=bss-postgres port=5432 user=replication''' >> /var/lib/postgresql/data/postgresql.conf
      echo 'primary_slot_name = ''replica1_slot''' >> /var/lib/postgresql/data/postgresql.conf
      echo 'hot_standby = on' >> /var/lib/postgresql/data/postgresql.conf
      echo 'hot_standby_feedback = on' >> /var/lib/postgresql/data/postgresql.conf
      su - postgres -c 'postgres -D /var/lib/postgresql/data'
      "

  # ================================
  # PostgreSQL Read Replica 2
  # ================================
  postgres-replica-2:
    image: postgres:18-alpine
    container_name: bss-postgres-replica-2
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_MASTER_SERVICE: bss-postgres
      POSTGRES_REPLICA_MODE: slave
    ports:
      - "5434:5432"
    volumes:
      - postgres-replica-2-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - bss-net
    command: >
      bash -c "
      echo 'Checking if primary is ready...'
      until pg_isready -h bss-postgres -p 5432; do
        sleep 2
      done
      echo 'Primary is ready, starting replica...'
      rm -f /var/lib/postgresql/data/postmaster.pid
      su - postgres -c 'pg_basebackup -h bss-postgres -p 5432 -D /var/lib/postgresql/data -U replication -v -P -R'
      echo 'standby_mode = on' > /var/lib/postgresql/data/postgresql.conf
      echo 'primary_conninfo = ''host=bss-postgres port=5432 user=replication''' >> /var/lib/postgresql/data/postgresql.conf
      echo 'primary_slot_name = ''replica2_slot''' >> /var/lib/postgresql/data/postgresql.conf
      echo 'hot_standby = on' >> /var/lib/postgresql/data/postgresql.conf
      echo 'hot_standby_feedback = on' >> /var/lib/postgresql/data/postgresql.conf
      su - postgres -c 'postgres -D /var/lib/postgresql/data'
      "

  # ================================
  # HAProxy - Database Load Balancer
  # ================================
  haproxy:
    image: haproxy:2.9
    container_name: bss-haproxy
    restart: unless-stopped
    volumes:
      - ./haproxy/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
    ports:
      - "5435:5432"
    healthcheck:
      test: ["CMD", "haproxy", "-c", "-f", "/usr/local/etc/haproxy/haproxy.cfg"]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      postgres:
        condition: service_healthy
      postgres-replica-1:
        condition: service_healthy
      postgres-replica-2:
        condition: service_healthy
    networks:
      - bss-net

  # ================================
  # Advanced Monitoring - AlertManager
  # ================================
  alertmanager:
    image: prom/alertmanager:v0.27.0
    container_name: bss-alertmanager
    restart: unless-stopped
    volumes:
      - ./alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
      - alertmanager-data:/alertmanager
    ports:
      - "9093:9093"
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
      - '--web.external-url=http://localhost:9093'
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9093/-/healthy"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # Advanced Monitoring - Node Exporter
  # ================================
  node-exporter:
    image: prom/node-exporter:v1.7.0
    container_name: bss-node-exporter
    restart: unless-stopped
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    ports:
      - "9100:9100"
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9100/metrics"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # Database Monitoring - pgMonitor
  # ================================
  pgmonitor:
    image: promcommunity/postgres_exporter:v0.15.0
    container_name: bss-pgmonitor
    restart: unless-stopped
    environment:
      DATA_SOURCE_NAME: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}?sslmode=disable
    ports:
      - "9187:9187"
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9187/metrics"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # PHASE 4: ADVANCED SCALE
  # ================================

  # ================================
  # Citus - Database Sharding (Coordinator)
  # ================================
  citus-coordinator:
    image: citusdata/citus:12.1.1
    container_name: bss-citus-coordinator
    restart: unless-stopped
    environment:
      POSTGRES_HOST_AUTH_METHOD: scram-sha-256
    ports:
      - "5436:5432"
    volumes:
      - citus-coordinator-data:/var/lib/postgresql/data
      - ./citus/coordinator:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # Citus - Database Sharding (Worker 1)
  # ================================
  citus-worker-1:
    image: citusdata/citus:12.1.1
    container_name: bss-citus-worker-1
    restart: unless-stopped
    environment:
      POSTGRES_HOST_AUTH_METHOD: scram-sha-256
    ports:
      - "5437:5432"
    volumes:
      - citus-worker-1-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      citus-coordinator:
        condition: service_healthy
    networks:
      - bss-net

  # ================================
  # Citus - Database Sharding (Worker 2)
  # ================================
  citus-worker-2:
    image: citusdata/citus:12.1.1
    container_name: bss-citus-worker-2
    restart: unless-stopped
    environment:
      POSTGRES_HOST_AUTH_METHOD: scram-sha-256
    ports:
      - "5438:5432"
    volumes:
      - citus-worker-2-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      citus-coordinator:
        condition: service_healthy
    networks:
      - bss-net

  # ================================
  # Citus - Database Sharding (Worker 3)
  # ================================
  citus-worker-3:
    image: citusdata/citus:12.1.1
    container_name: bss-citus-worker-3
    restart: unless-stopped
    environment:
      POSTGRES_HOST_AUTH_METHOD: scram-sha-256
    ports:
      - "5439:5432"
    volumes:
      - citus-worker-3-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      citus-coordinator:
        condition: service_healthy
    networks:
      - bss-net

  # ================================
  # Apache Flink - Stream Processing
  # ================================
  flink-jobmanager:
    image: apache/flink:1.18.1-scala_2.12-java11
    container_name: bss-flink-jobmanager
    restart: unless-stopped
    ports:
      - "8081:8081"  # Web UI
      - "6123:6123"  # RPC
    command: jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        parallelism.default: 2
    volumes:
      - flink-data:/opt/flink/data
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
    networks:
      - bss-net

  # ================================
  # Apache Flink - Task Manager
  # ================================
  flink-taskmanager:
    image: apache/flink:1.18.1-scala_2.12-java11
    container_name: bss-flink-taskmanager
    restart: unless-stopped
    scale: 2
    command: taskmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        taskmanager.numberOfTaskSlots: 4
        parallelism.default: 2
    volumes:
      - flink-data:/opt/flink/data
    depends_on:
      - flink-jobmanager
    networks:
      - bss-net

  # ================================
  # ArgoCD (GitOps)
  # ================================
  argocd:
    image: quay.io/argoproj/argocd:v2.9.0
    container_name: bss-argocd
    restart: unless-stopped
    command:
      - argocd-server
      - --redis
      - argocd-redis
      - --repo-server
      - argocd-repo-server
      - --insecure
    ports:
      - "8080:8080"  # ArgoCD UI and API
    volumes:
      - argocd-data:/tmp/argocd-data
    environment:
      - ARGOCD_REPO_SERVER_LOGLEVEL=info
      - ARGOCD_SERVER_LOGLEVEL=info
    depends_on:
      - argocd-redis
      - argocd-repo-server
    networks:
      - bss-net

  # ArgoCD Redis
  argocd-redis:
    image: quay.io/argoproj/argocd:v2.9.0
    container_name: bss-argocd-redis
    restart: unless-stopped
    command:
      - redis-server
      - --requirepass
      - ${ARGOCD_REDIS_PASSWORD:-admin}
    networks:
      - bss-net

  # ArgoCD Repo Server
  argocd-repo-server:
    image: quay.io/argoproj/argocd:v2.9.0
    container_name: bss-argocd-repo-server
    restart: unless-stopped
    command:
      - entrypoint.sh
      - argocd-repo-server
      - --loglevel=info
    volumes:
      - argocd-data:/tmp/argocd-data
    networks:
      - bss-net

  # ================================
  # HashiCorp Vault (Secrets Management)
  # ================================
  vault:
    image: hashicorp/vault:1.17.0
    container_name: bss-vault
    restart: unless-stopped
    cap_add:
      - IPC_LOCK
    environment:
      - VAULT_DEV_ROOT_TOKEN_ID=dev-only-token
      - VAULT_DEV_LISTEN_ADDRESS=0.0.0.0:8200
      - VAULT_ADDR=http://0.0.0.0:8200
    ports:
      - "8200:8200"  # Vault UI and API
    volumes:
      - vault-data:/vault/data
    networks:
      - bss-net

volumes:
  postgres-data:
  redis-data:
  caddy-config:
  caddy-data:
  # Observability volumes
  tempo-data:
  loki-data:
  grafana-data:
  prometheus-data:
  # Phase 1 additional volumes
  elasticsearch-data:
  # Phase 2 volumes
  zookeeper-data:
  zookeeper-logs:
  kafka-1-data:
  kafka-2-data:
  kafka-3-data:
  schema-registry-data:
  redis-cluster-data:
  traefik-data:
  # Phase 3 volumes
  postgres-replica-1-data:
  postgres-replica-2-data:
  alertmanager-data:
  # Phase 4 volumes
  citus-coordinator-data:
  citus-worker-1-data:
  citus-worker-2-data:
  citus-worker-3-data:
  flink-data:
  # ArgoCD volume
  argocd-data:
  # RedisInsight volume
  redisinsight-data:
  # Vault volume
  vault-data:

networks:
  bss-net:
    driver: bridge
