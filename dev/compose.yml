version: "3.9"

x-common-env: &common-environment
  SPRING_PROFILES_ACTIVE: dev

services:
  postgres:
    image: postgres:18-alpine
    container_name: bss-postgres
    restart: unless-stopped
    env_file:
      - ../.env
    environment:
      POSTGRES_HOST_AUTH_METHOD: trust
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  redis:
    image: redis:7-alpine
    container_name: bss-redis
    restart: unless-stopped
    command: redis-server --save 20 1 --loglevel warning
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  keycloak:
    image: quay.io/keycloak/keycloak:26.0
    container_name: bss-keycloak
    restart: unless-stopped
    command:
      - start-dev
      - --import-realm
      - --http-enabled=true
      - --health-enabled=true
      - --cache-config-file=/opt/keycloak/conf/keycloak-cache-ispn.xml
    env_file:
      - ../.env
    environment:
      KEYCLOAK_IMPORT: /opt/keycloak/data/import/realm-bss.json
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_SESSION_DB: 1
      # Cache configuration
      CACHE_OWNERS_COUNT: "1"
      CACHE_OWNERS_AUTH_SESSIONS_COUNT: "1"
      CACHE_OWNERS_ACCOUNT_SESSIONS_COUNT: "1"
    volumes:
      - ../infra/keycloak:/opt/keycloak/data/import:ro
      - ../infra/keycloak/conf/keycloak-cache-ispn.xml:/opt/keycloak/conf/keycloak-cache-ispn.xml:ro
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    ports:
      - "8081:8080"
    healthcheck:
      test:
        - CMD-SHELL
        - exec 3<>/dev/tcp/127.0.0.1/9000 && printf "GET /health/ready HTTP/1.0\r\n\r\n" >&3 && read -r line <&3 && exec 3>&- && case "$$line" in *200*) exit 0 ;; *) exit 1 ;; esac
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 20s
    networks:
      - bss-net

  backend:
    build:
      context: ../backend
      dockerfile: Dockerfile
    container_name: bss-backend
    restart: unless-stopped
    env_file:
      - ../.env
    environment:
      <<: *common-environment
      SPRING_REDIS_HOST: redis
      # TLS Configuration
      SERVER_SSL_ENABLED: "true"
      SERVER_SSL_KEY_STORE: /etc/ssl/certs/backend-cert.p12
      SERVER_SSL_KEY_STORE_PASSWORD: "changeit"
      SERVER_SSL_KEY_STORE_TYPE: PKCS12
      SERVER_SSL_TRUST_STORE: /etc/ssl/certs/truststore.jks
      SERVER_SSL_TRUST_STORE_PASSWORD: "changeit"
      SERVER_SSL_CLIENT_AUTH_ENABLED: "true"
      SERVER_SSL_ENABLED_PROTOCOLS: TLSv1.2,TLSv1.3
      SERVER_SSL_CIPHERS: TLS_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      keycloak:
        condition: service_healthy
    ports:
      - "8080:8080"   # HTTP
      - "8443:8443"   # HTTPS/mTLS
    volumes:
      - ./certs/server:/etc/ssl/certs:ro
      - ./certs/ca:/etc/ssl/ca:ro
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:8080/actuator/health | grep UP"]
      interval: 15s
      timeout: 5s
      retries: 10
      start_period: 30s
    networks:
      - bss-net

  frontend:
    build:
      context: ../frontend
      dockerfile: Dockerfile
    container_name: bss-frontend
    restart: unless-stopped
    env_file:
      - ../.env
    environment:
      NUXT_PUBLIC_API_BASE_URL: http://backend:8080
      NUXT_PUBLIC_KEYCLOAK_URL: http://keycloak:8080
      NUXT_PUBLIC_KEYCLOAK_REALM: bss
      NUXT_PUBLIC_KEYCLOAK_CLIENT_ID: ${KEYCLOAK_FRONTEND_CLIENT_ID}
    depends_on:
      backend:
        condition: service_healthy
    ports:
      - "3000:3000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/"]
      interval: 15s
      timeout: 5s
      retries: 10
      start_period: 30s
    networks:
      - bss-net

  caddy:
    image: caddy:2.9.1-alpine
    container_name: bss-caddy
    restart: unless-stopped
    depends_on:
      backend:
        condition: service_healthy
      frontend:
        condition: service_healthy
      keycloak:
        condition: service_started
    volumes:
      - ./caddy/Caddyfile:/etc/caddy/Caddyfile:ro
      - ./certs:/certs:ro
      - caddy-config:/config
      - caddy-data:/data
    ports:
      - "8085:80"
      - "8443:443"
    healthcheck:
      test:
        - CMD-SHELL
        - wget -q --spider http://127.0.0.1/healthz || exit 1
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - bss-net

  # ================================
  # Observability Stack - Tempo (Traces)
  # ================================
  tempo:
    image: grafana/tempo:2.6.1
    container_name: bss-tempo
    restart: unless-stopped
    command: -config.file=/etc/tempo.yaml
    ports:
      - "3200:3200"   # Tempo HTTP
      - "4317:4317"   # OTLP gRPC
      - "4318:4318"   # OTLP HTTP
    volumes:
      - ./tempo/tempo.yaml:/etc/tempo.yaml:ro
      - tempo-data:/var/lib/tempo
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3200/ready"]
      interval: 15s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # Observability Stack - Loki (Logs)
  # ================================
  loki:
    image: grafana/loki:3.3.0
    container_name: bss-loki
    restart: unless-stopped
    command: -config.file=/etc/loki/local-config.yaml
    ports:
      - "3100:3100"
    volumes:
      - ./loki/loki-config.yaml:/etc/loki/local-config.yaml:ro
      - loki-data:/var/loki
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3100/ready"]
      interval: 15s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # Observability Stack - Promtail (Log Collector)
  # ================================
  promtail:
    image: grafana/promtail:3.3.0
    container_name: bss-promtail
    restart: unless-stopped
    command: -config.file=/etc/promtail/config.yml
    volumes:
      - ./promtail/promtail-config.yml:/etc/promtail/config.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      - loki
    networks:
      - bss-net

  # ================================
  # Observability Stack - Grafana (Dashboards)
  # ================================
  grafana:
    image: grafana/grafana:11.2.0
    container_name: bss-grafana
    restart: unless-stopped
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_AUTH_ANONYMOUS_ENABLED=false
      - GF_SECURITY_DISABLE_GRAVATAR=true
      - GF_ANALYTICS_REPORTING_ENABLED=false
      - GF_ANALYTICS_CHECK_FOR_UPDATES=false
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
    depends_on:
      - prometheus
      - tempo
      - loki
    ports:
      - "3001:3000"
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000/api/health || exit 1"]
      interval: 15s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # Observability Stack - Prometheus (Metrics)
  # ================================
  prometheus:
    image: prom/prometheus:v2.55.1
    container_name: bss-prometheus
    restart: unless-stopped
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    ports:
      - "9090:9090"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 15s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # Observability Stack - Jaeger (Distributed Tracing)
  # ================================
  jaeger:
    image: jaegertracing/all-in-one:1.62
    container_name: bss-jaeger
    restart: unless-stopped
    environment:
      - COLLECTOR_OTLP_ENABLED=true
      - SPAN_STORAGE_TYPE=elasticsearch
      - ES_SERVER_URLS=http://elasticsearch:9200
      - ES_NUM_SHARDS=1
      - ES_NUM_REPLICAS=0
    depends_on:
      - elasticsearch
    ports:
      - "16686:16686"  # Jaeger UI
      - "14268:14268"  # HTTP collector
      - "14250:14250"  # gRPC collector
    networks:
      - bss-net

  # ================================
  # Elasticsearch (for Jaeger)
  # ================================
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.14.0
    container_name: bss-elasticsearch
    restart: unless-stopped
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9200/_cluster/health"]
      interval: 15s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # PgBouncer (PostgreSQL Connection Pooling)
  # ================================
  pgbouncer:
    image: pgbouncer/pgbouncer:1.25.0
    container_name: bss-pgbouncer
    restart: unless-stopped
    env_file:
      - ../.env
    environment:
      - DATABASES_HOST=postgres
      - DATABASES_PORT=5432
      - DATABASES_USER=${POSTGRES_USER}
      - DATABASES_PASSWORD=${POSTGRES_PASSWORD}
      - DATABASES_DBNAME=${POSTGRES_DB}
      - POOL_MODE=transaction
      - MAX_CLIENT_CONN=100
      - DEFAULT_POOL_SIZE=20
      - MIN_POOL_SIZE=5
      - RESERVE_POOL_SIZE=5
      - SERVER_LIFETIME=3600
      - SERVER_IDLE_TIMEOUT=600
      - LOG_CONNECTIONS=1
      - LOG_POOLER_ERRORS=1
    ports:
      - "6432:5432"
    depends_on:
      postgres:
        condition: service_healthy
    volumes:
      - ./pgbouncer/pgbouncer.ini:/etc/pgbouncer/pgbouncer.ini:ro
      - ./pgbouncer/userlist.txt:/etc/pgbouncer/userlist.txt:ro
    healthcheck:
      test: ["CMD", "psql", "-h", "localhost", "-p", "5432", "-U", "${POSTGRES_USER}", "-d", "${POSTGRES_DB}", "-c", "SELECT 1"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # PgHero (Query Analysis & Performance)
  # ================================
  pghero:
    image: ankane/pghero:v3.4.0
    container_name: bss-pghero
    restart: unless-stopped
    env_file:
      - ../.env
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      - SECRET_KEY_BASE=${PGHERO_SECRET_KEY_BASE:-secret_key_base_change_in_production}
    ports:
      - "8082:3000"
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - bss-net

  # ================================
  # PHASE 2: CORE INFRASTRUCTURE
  # ================================

  # ================================
  # Zookeeper (for Kafka)
  # ================================
  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.0
    container_name: bss-zookeeper
    restart: unless-stopped
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data
      - zookeeper-logs:/var/lib/zookeeper/log
    healthcheck:
      test: ["CMD", "zk", "status"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # Kafka Brokers (Cluster)
  # ================================
  kafka-1:
    image: confluentinc/cp-kafka:7.6.0
    container_name: bss-kafka-1
    restart: unless-stopped
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-1:9092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_RETENTION_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      KAFKA_JVM_PERFORMANCE_OPTS: -Xms512m -Xmx512m
    volumes:
      - kafka-1-data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 15s
      timeout: 10s
      retries: 5
    networks:
      - bss-net

  kafka-2:
    image: confluentinc/cp-kafka:7.6.0
    container_name: bss-kafka-2
    restart: unless-stopped
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-2:9092,PLAINTEXT_HOST://localhost:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_JVM_PERFORMANCE_OPTS: -Xms512m -Xmx512m
    volumes:
      - kafka-2-data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 15s
      timeout: 10s
      retries: 5
    networks:
      - bss-net

  kafka-3:
    image: confluentinc/cp-kafka:7.6.0
    container_name: bss-kafka-3
    restart: unless-stopped
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-3:9092,PLAINTEXT_HOST://localhost:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_JVM_PERFORMANCE_OPTS: -Xms512m -Xmx512m
    volumes:
      - kafka-3-data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 15s
      timeout: 10s
      retries: 5
    networks:
      - bss-net

  # ================================
  # Redis Cluster (Enhanced)
  # ================================
  redis-cluster:
    image: redis:7-alpine
    container_name: bss-redis-cluster
    restart: unless-stopped
    command: >
      redis-server
      --cluster-enabled yes
      --cluster-config-file nodes.conf
      --cluster-node-timeout 5000
      --appendonly yes
      --save 20 1
      --loglevel warning
    ports:
      - "7000:7000"  # Cluster port
      - "7001:7001"  # Cluster bus port
    volumes:
      - redis-cluster-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # AKHQ (Kafka UI & Monitoring)
  # ================================
  akhq:
    image: tchiotludo/akhq:0.24.0
    container_name: bss-akhq
    restart: unless-stopped
    environment:
      AKHQ_CONFIGURATION: |
        akhq:
          connections:
            docker-kafka-server:
              properties:
                bootstrap.servers: kafka-1:9092,kafka-2:9092,kafka-3:9092
      AKHQ_OPTS: -Xms256m -Xmx512m
    ports:
      - "8083:8080"
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/health"]
      interval: 15s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # RedisInsight (Redis GUI)
  # ================================
  redisinsight:
    image: redislabs/redisinsight:latest
    container_name: bss-redisinsight
    restart: unless-stopped
    ports:
      - "8001:8001"
    volumes:
      - redisinsight-data:/db
    environment:
      - RITRUSTEDORIGINS=http://localhost:8001
    networks:
      - bss-net
    depends_on:
      redis:
        condition: service_healthy
      redis-cluster:
        condition: service_healthy

  # ================================
  # Kong API Gateway
  # ================================
  kong-db:
    image: postgres:18-alpine
    container_name: bss-kong-db
    restart: unless-stopped
    environment:
      POSTGRES_DB: kong
      POSTGRES_USER: kong
      POSTGRES_PASSWORD: kong_password
    volumes:
      - kong-db-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U kong"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  kong-migrations:
    image: kong:3.5
    container_name: bss-kong-migrations
    restart: "no"
    depends_on:
      kong-db:
        condition: service_healthy
    environment:
      KONG_DATABASE: postgres
      KONG_PG_HOST: kong-db
      KONG_PG_USER: kong
      KONG_PG_PASSWORD: kong_password
      KONG_PG_DATABASE: kong
    command: ["kong", "migrations", "bootstrap"]
    networks:
      - bss-net

  kong:
    image: kong:3.5
    container_name: bss-kong
    restart: unless-stopped
    depends_on:
      - kong-migrations
    environment:
      KONG_DATABASE: postgres
      KONG_PG_HOST: kong-db
      KONG_PG_USER: kong
      KONG_PG_PASSWORD: kong_password
      KONG_PG_DATABASE: kong
      KONG_PROXY_ACCESS_LOG: /dev/stdout
      KONG_ADMIN_ACCESS_LOG: /dev/stdout
      KONG_PROXY_ERROR_LOG: /dev/stderr
      KONG_ADMIN_ERROR_LOG: /dev/stderr
      KONG_ADMIN_LISTEN: 0.0.0.0:8001
      KONG_PROXY_LISTEN: 0.0.0.0:8000
      KONG_PROXY_LISTEN_SSL: 0.0.0.0:8443
      # mTLS Configuration
      KONG_SSL_CERT: /etc/kong/certs/kong-cert.pem
      KONG_SSL_CERT_KEY: /etc/kong/certs/kong-key.pem
      KONG_LUA_SSL_TRUSTED_CERTIFICATE: /etc/kong/certs/ca-cert.pem
      KONG_LUA_SSL_VERIFY_DEPTH: 5
      KONG_SSL_ECC: "true"
    ports:
      - "8000:8000"   # Proxy HTTP
      - "8443:8443"   # Proxy HTTPS
      - "8001:8001"   # Admin API
      - "8444:8444"   # Admin API HTTPS
    volumes:
      - ./kong/kong.yml:/usr/local/kong/kong.yml:ro
      - ./certs/server:/etc/kong/certs:ro
      - ./certs/ca:/etc/kong/ca:ro
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8000/"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # PHASE 3: NETWORK & PROCESSING
  # ================================

  # ================================
  # Service Mesh - Envoy Proxy
  # ================================
  envoy:
    image: envoyproxy/envoy:v1.29.0
    container_name: bss-envoy
    restart: unless-stopped
    volumes:
      - ./envoy/envoy.yaml:/etc/envoy/envoy.yaml:ro
    ports:
      - "15001:15001"  # Admin port
      - "15006:15006"  # Proxy port
    command: ["-c", "/etc/envoy/envoy.yaml", "-l", "info"]
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:15000/ready"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # Kafka Streams - Customer Analytics
  # ================================
  kafka-streams-customer-analytics:
    image: confluentinc/cp-kafka:7.6.0
    container_name: bss-kafka-streams-customer
    restart: unless-stopped
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
    environment:
      BOOTSTRAP_SERVERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
      APPLICATION_ID: bss-customer-analytics
      INPUT_TOPIC: bss.customer.events
      OUTPUT_TOPIC: bss.analytics.events
    volumes:
      - ./kafka-streams/customer-analytics:/scripts
    command: ["sh", "/scripts/run.sh"]
    healthcheck:
      test: ["CMD", "pgrep", "-f", "kafka-console-consumer"]
      interval: 15s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # Kafka Streams - Order Processing
  # ================================
  kafka-streams-order-processor:
    image: confluentinc/cp-kafka:7.6.0
    container_name: bss-kafka-streams-order
    restart: unless-stopped
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
    environment:
      BOOTSTRAP_SERVERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
      APPLICATION_ID: bss-order-processor
      INPUT_TOPIC: bss.order.events
      OUTPUT_TOPIC: bss.analytics.events
    volumes:
      - ./kafka-streams/order-processor:/scripts
    command: ["sh", "/scripts/run.sh"]
    healthcheck:
      test: ["CMD", "pgrep", "-f", "kafka-console-consumer"]
      interval: 15s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # PostgreSQL Read Replica 1
  # ================================
  postgres-replica-1:
    image: postgres:18-alpine
    container_name: bss-postgres-replica-1
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_MASTER_SERVICE: bss-postgres
      POSTGRES_REPLICA_MODE: slave
    ports:
      - "5433:5432"
    volumes:
      - postgres-replica-1-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - bss-net
    command: >
      bash -c "
      echo 'Checking if primary is ready...'
      until pg_isready -h bss-postgres -p 5432; do
        sleep 2
      done
      echo 'Primary is ready, starting replica...'
      rm -f /var/lib/postgresql/data/postmaster.pid
      su - postgres -c 'pg_basebackup -h bss-postgres -p 5432 -D /var/lib/postgresql/data -U replication -v -P -R'
      echo 'standby_mode = on' > /var/lib/postgresql/data/postgresql.conf
      echo 'primary_conninfo = ''host=bss-postgres port=5432 user=replication''' >> /var/lib/postgresql/data/postgresql.conf
      echo 'primary_slot_name = ''replica1_slot''' >> /var/lib/postgresql/data/postgresql.conf
      echo 'hot_standby = on' >> /var/lib/postgresql/data/postgresql.conf
      echo 'hot_standby_feedback = on' >> /var/lib/postgresql/data/postgresql.conf
      su - postgres -c 'postgres -D /var/lib/postgresql/data'
      "

  # ================================
  # PostgreSQL Read Replica 2
  # ================================
  postgres-replica-2:
    image: postgres:18-alpine
    container_name: bss-postgres-replica-2
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_MASTER_SERVICE: bss-postgres
      POSTGRES_REPLICA_MODE: slave
    ports:
      - "5434:5432"
    volumes:
      - postgres-replica-2-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - bss-net
    command: >
      bash -c "
      echo 'Checking if primary is ready...'
      until pg_isready -h bss-postgres -p 5432; do
        sleep 2
      done
      echo 'Primary is ready, starting replica...'
      rm -f /var/lib/postgresql/data/postmaster.pid
      su - postgres -c 'pg_basebackup -h bss-postgres -p 5432 -D /var/lib/postgresql/data -U replication -v -P -R'
      echo 'standby_mode = on' > /var/lib/postgresql/data/postgresql.conf
      echo 'primary_conninfo = ''host=bss-postgres port=5432 user=replication''' >> /var/lib/postgresql/data/postgresql.conf
      echo 'primary_slot_name = ''replica2_slot''' >> /var/lib/postgresql/data/postgresql.conf
      echo 'hot_standby = on' >> /var/lib/postgresql/data/postgresql.conf
      echo 'hot_standby_feedback = on' >> /var/lib/postgresql/data/postgresql.conf
      su - postgres -c 'postgres -D /var/lib/postgresql/data'
      "

  # ================================
  # HAProxy - Database Load Balancer
  # ================================
  haproxy:
    image: haproxy:2.9
    container_name: bss-haproxy
    restart: unless-stopped
    volumes:
      - ./haproxy/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
    ports:
      - "5435:5432"
    healthcheck:
      test: ["CMD", "haproxy", "-c", "-f", "/usr/local/etc/haproxy/haproxy.cfg"]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      postgres:
        condition: service_healthy
      postgres-replica-1:
        condition: service_healthy
      postgres-replica-2:
        condition: service_healthy
    networks:
      - bss-net

  # ================================
  # Advanced Monitoring - AlertManager
  # ================================
  alertmanager:
    image: prom/alertmanager:v0.27.0
    container_name: bss-alertmanager
    restart: unless-stopped
    volumes:
      - ./alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
      - alertmanager-data:/alertmanager
    ports:
      - "9093:9093"
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
      - '--web.external-url=http://localhost:9093'
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9093/-/healthy"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # Advanced Monitoring - Node Exporter
  # ================================
  node-exporter:
    image: prom/node-exporter:v1.7.0
    container_name: bss-node-exporter
    restart: unless-stopped
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    ports:
      - "9100:9100"
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9100/metrics"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # Database Monitoring - pgMonitor
  # ================================
  pgmonitor:
    image: promcommunity/postgres_exporter:v0.15.0
    container_name: bss-pgmonitor
    restart: unless-stopped
    environment:
      DATA_SOURCE_NAME: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}?sslmode=disable
    ports:
      - "9187:9187"
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9187/metrics"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # PHASE 4: ADVANCED SCALE
  # ================================

  # ================================
  # Citus - Database Sharding (Coordinator)
  # ================================
  citus-coordinator:
    image: citusdata/citus:12.1.1
    container_name: bss-citus-coordinator
    restart: unless-stopped
    environment:
      POSTGRES_HOST_AUTH_METHOD: trust
    ports:
      - "5436:5432"
    volumes:
      - citus-coordinator-data:/var/lib/postgresql/data
      - ./citus/coordinator:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - bss-net

  # ================================
  # Citus - Database Sharding (Worker 1)
  # ================================
  citus-worker-1:
    image: citusdata/citus:12.1.1
    container_name: bss-citus-worker-1
    restart: unless-stopped
    environment:
      POSTGRES_HOST_AUTH_METHOD: trust
    ports:
      - "5437:5432"
    volumes:
      - citus-worker-1-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      citus-coordinator:
        condition: service_healthy
    networks:
      - bss-net

  # ================================
  # Citus - Database Sharding (Worker 2)
  # ================================
  citus-worker-2:
    image: citusdata/citus:12.1.1
    container_name: bss-citus-worker-2
    restart: unless-stopped
    environment:
      POSTGRES_HOST_AUTH_METHOD: trust
    ports:
      - "5438:5432"
    volumes:
      - citus-worker-2-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      citus-coordinator:
        condition: service_healthy
    networks:
      - bss-net

  # ================================
  # Citus - Database Sharding (Worker 3)
  # ================================
  citus-worker-3:
    image: citusdata/citus:12.1.1
    container_name: bss-citus-worker-3
    restart: unless-stopped
    environment:
      POSTGRES_HOST_AUTH_METHOD: trust
    ports:
      - "5439:5432"
    volumes:
      - citus-worker-3-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      citus-coordinator:
        condition: service_healthy
    networks:
      - bss-net

  # ================================
  # Apache Flink - Stream Processing
  # ================================
  flink-jobmanager:
    image: apache/flink:1.18.1-scala_2.12-java11
    container_name: bss-flink-jobmanager
    restart: unless-stopped
    ports:
      - "8081:8081"  # Web UI
      - "6123:6123"  # RPC
    command: jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        parallelism.default: 2
    volumes:
      - flink-data:/opt/flink/data
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
    networks:
      - bss-net

  # ================================
  # Apache Flink - Task Manager
  # ================================
  flink-taskmanager:
    image: apache/flink:1.18.1-scala_2.12-java11
    container_name: bss-flink-taskmanager
    restart: unless-stopped
    scale: 2
    command: taskmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        taskmanager.numberOfTaskSlots: 4
        parallelism.default: 2
    volumes:
      - flink-data:/opt/flink/data
    depends_on:
      - flink-jobmanager
    networks:
      - bss-net

  # ================================
  # ArgoCD (GitOps)
  # ================================
  argocd:
    image: quay.io/argoproj/argocd:v2.9.0
    container_name: bss-argocd
    restart: unless-stopped
    command:
      - argocd-server
      - --redis
      - argocd-redis
      - --repo-server
      - argocd-repo-server
      - --insecure
    ports:
      - "8080:8080"  # ArgoCD UI and API
    volumes:
      - argocd-data:/tmp/argocd-data
    environment:
      - ARGOCD_REPO_SERVER_LOGLEVEL=info
      - ARGOCD_SERVER_LOGLEVEL=info
    depends_on:
      - argocd-redis
      - argocd-repo-server
    networks:
      - bss-net

  # ArgoCD Redis
  argocd-redis:
    image: quay.io/argoproj/argocd:v2.9.0
    container_name: bss-argocd-redis
    restart: unless-stopped
    command:
      - redis-server
      - --requirepass
      - ${ARGOCD_REDIS_PASSWORD:-admin}
    networks:
      - bss-net

  # ArgoCD Repo Server
  argocd-repo-server:
    image: quay.io/argoproj/argocd:v2.9.0
    container_name: bss-argocd-repo-server
    restart: unless-stopped
    command:
      - entrypoint.sh
      - argocd-repo-server
      - --loglevel=info
    volumes:
      - argocd-data:/tmp/argocd-data
    networks:
      - bss-net

  # ================================
  # HashiCorp Vault (Secrets Management)
  # ================================
  vault:
    image: hashicorp/vault:1.17.0
    container_name: bss-vault
    restart: unless-stopped
    cap_add:
      - IPC_LOCK
    environment:
      - VAULT_DEV_ROOT_TOKEN_ID=dev-only-token
      - VAULT_DEV_LISTEN_ADDRESS=0.0.0.0:8200
      - VAULT_ADDR=http://0.0.0.0:8200
    ports:
      - "8200:8200"  # Vault UI and API
    volumes:
      - vault-data:/vault/data
    networks:
      - bss-net

volumes:
  postgres-data:
  redis-data:
  caddy-config:
  caddy-data:
  # Observability volumes
  tempo-data:
  loki-data:
  grafana-data:
  prometheus-data:
  # Phase 1 additional volumes
  elasticsearch-data:
  # Phase 2 volumes
  zookeeper-data:
  zookeeper-logs:
  kafka-1-data:
  kafka-2-data:
  kafka-3-data:
  redis-cluster-data:
  kong-db-data:
  # Phase 3 volumes
  postgres-replica-1-data:
  postgres-replica-2-data:
  alertmanager-data:
  # Phase 4 volumes
  citus-coordinator-data:
  citus-worker-1-data:
  citus-worker-2-data:
  citus-worker-3-data:
  flink-data:
  # ArgoCD volume
  argocd-data:
  # RedisInsight volume
  redisinsight-data:
  # Vault volume
  vault-data:

networks:
  bss-net:
    driver: bridge
