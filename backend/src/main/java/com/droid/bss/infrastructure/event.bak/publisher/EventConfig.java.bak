package com.droid.bss.infrastructure.event.publisher;

import com.fasterxml.jackson.databind.ObjectMapper;
import io.cloudevents.CloudEvent;
import io.cloudevents.core.data.PojoCloudEventData;
import io.cloudevents.core.provider.EventRenderer;
import io.cloudevents.jackson.JsonFormat;
import org.apache.kafka.clients.admin.AdminClientConfig;
import org.apache.kafka.clients.admin.NewTopic;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.common.serialization.StringSerializer;
import org.springframework.boot.autoconfigure.condition.ConditionalOnClass;
import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;
import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;
import org.springframework.boot.autoconfigure.kafka.KafkaProperties;
import org.springframework.boot.context.properties.EnableConfigurationProperties;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.annotation.Primary;
import org.springframework.kafka.annotation.EnableKafka;
import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory;
import org.springframework.kafka.config.TopicBuilder;
import org.springframework.kafka.core.*;
import org.springframework.kafka.support.mapping.DefaultJackson2JavaTypeMapper;
import org.springframework.kafka.support.mapping.JavaTypeMapper;
import org.springframework.scheduling.annotation.EnableAsync;
import org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;

import java.util.HashMap;
import java.util.Map;
import java.util.concurrent.Executor;

/**
 * Spring configuration for event publishing infrastructure.
 *
 * @since 1.0
 */
@Configuration
@EnableKafka
@EnableAsync
@EnableConfigurationProperties(EventProperties.class)
@ConditionalOnProperty(name = "app.event.enabled", havingValue = "true", matchIfMissing = true)
public class EventConfig {

    private final EventProperties eventProperties;
    private final KafkaProperties kafkaProperties;

    public EventConfig(EventProperties eventProperties, KafkaProperties kafkaProperties) {
        this.eventProperties = eventProperties;
        this.kafkaProperties = kafkaProperties;
    }

    /**
     * Creates the Kafka template for event publishing.
     *
     * @param producerFactory the producer factory
     * @return the Kafka template
     */
    @Bean
    @Primary
    public KafkaTemplate<String, Object> kafkaTemplate(ProducerFactory<String, Object> producerFactory) {
        return new KafkaTemplate<>(producerFactory);
    }

    /**
     * Creates the producer factory for Kafka.
     *
     * @return the producer factory
     */
    @Bean
    public ProducerFactory<String, Object> producerFactory() {
        Map<String, Object> configs = new HashMap<>();
        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaProperties.getBootstrapServers());
        configs.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        configs.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, KafkaEventSerializer.class);
        configs.put(ProducerConfig.ACKS_CONFIG, "all");
        configs.put(ProducerConfig.RETRIES_CONFIG, eventProperties.getMaxRetries());
        configs.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);
        configs.put(ProducerConfig.LINGER_MS_CONFIG, 5);
        configs.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 33554432);

        configs.putAll(kafkaProperties.getProducer().getProperties());

        DefaultKafkaProducerFactory<String, Object> factory = new DefaultKafkaProducerFactory<>(configs);
        factory.setTransactionIdPrefix("tx-" + eventProperties.getTopicPrefix() + "-");
        return factory;
    }

    /**
     * Creates the Kafka admin client for topic management.
     *
     * @return the admin client
     */
    @Bean
    public KafkaAdmin kafkaAdmin() {
        Map<String, Object> configs = new HashMap<>();
        configs.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaProperties.getBootstrapServers());
        configs.putAll(kafkaProperties.getAdmin().getProperties());
        return new KafkaAdmin(configs);
    }

    /**
     * Creates the default topic if it doesn't exist.
     *
     * @return the default topic bean
     */
    @Bean
    public NewTopic defaultTopic() {
        return TopicBuilder.name(eventProperties.getTopicPrefix() + ".default")
            .partitions(3)
            .replicas(3)
            .build();
    }

    /**
     * Creates the customer events topic.
     *
     * @return the customer events topic bean
     */
    @Bean
    public NewTopic customerEventsTopic() {
        return TopicBuilder.name(eventProperties.getTopicPrefix() + ".customer")
            .partitions(6)
            .replicas(3)
            .build();
    }

    /**
     * Creates the order events topic.
     *
     * @return the order events topic bean
     */
    @Bean
    public NewTopic orderEventsTopic() {
        return TopicBuilder.name(eventProperties.getTopicPrefix() + ".order")
            .partitions(6)
            .replicas(3)
            .build();
    }

    /**
     * Creates the invoice events topic.
     *
     * @return the invoice events topic bean
     */
    @Bean
    public NewTopic invoiceEventsTopic() {
        return TopicBuilder.name(eventProperties.getTopicPrefix() + ".invoice")
            .partitions(3)
            .replicas(3)
            .build();
    }

    /**
     * Creates the payment events topic.
     *
     * @return the payment events topic bean
     */
    @Bean
    public NewTopic paymentEventsTopic() {
        return TopicBuilder.name(eventProperties.getTopicPrefix() + ".payment")
            .partitions(6)
            .replicas(3)
            .build();
    }

    /**
     * Creates the subscription events topic.
     *
     * @return the subscription events topic bean
     */
    @Bean
    public NewTopic subscriptionEventsTopic() {
        return TopicBuilder.name(eventProperties.getTopicPrefix() + ".subscription")
            .partitions(3)
            .replicas(3)
            .build();
    }

    /**
     * Creates the service events topic.
     *
     * @return the service events topic bean
     */
    @Bean
    public NewTopic serviceEventsTopic() {
        return TopicBuilder.name(eventProperties.getTopicPrefix() + ".service")
            .partitions(3)
            .replicas(3)
            .build();
    }

    /**
     * Creates the default domain event publisher.
     *
     * @param kafkaTemplate the Kafka template
     * @param objectMapper the object mapper
     * @return the domain event publisher
     */
    @Bean
    @ConditionalOnMissingBean
    public DomainEventPublisher domainEventPublisher(KafkaTemplate<String, Object> kafkaTemplate,
                                                      ObjectMapper objectMapper) {
        return new KafkaEventPublisher(kafkaTemplate, objectMapper, eventProperties);
    }

    /**
     * Creates the async executor for event publishing.
     *
     * @return the executor
     */
    @Bean
    public Executor eventPublishingExecutor() {
        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
        executor.setCorePoolSize(eventProperties.getParallelism());
        executor.setMaxPoolSize(eventProperties.getParallelism() * 2);
        executor.setQueueCapacity(eventProperties.getBufferSize());
        executor.setThreadNamePrefix("event-publishing-");
        executor.setWaitForTasksToCompleteOnShutdown(true);
        executor.initialize();
        return executor;
    }

    /**
     * Kafka serializer for CloudEvents.
     */
    @ConditionalOnClass(CloudEvent.class)
    public static class KafkaEventSerializer implements org.apache.kafka.common.serialization.Serializer<CloudEvent> {

        @Override
        public void configure(Map<String, ?> configs, boolean isKey) {
            // No configuration needed
        }

        @Override
        public byte[] serialize(String topic, CloudEvent data) {
            if (data == null) {
                return null;
            }
            // CloudEvents are already serialized as byte[]
            return data.toBytes();
        }

        @Override
        public void close() {
            // Nothing to close
        }
    }

    /**
     * Kafka deserializer for CloudEvents (for consumers).
     */
    @ConditionalOnClass(CloudEvent.class)
    public static class KafkaEventDeserializer implements org.apache.kafka.common.serialization.Deserializer<CloudEvent> {

        @Override
        public void configure(Map<String, ?> configs, boolean isKey) {
            // No configuration needed
        }

        @Override
        public CloudEvent deserialize(String topic, byte[] data) {
            if (data == null) {
                return null;
            }
            // Deserialize from byte[] to CloudEvent
            try {
                return JsonFormat.getReader().read(data);
            } catch (Exception e) {
                throw new RuntimeException("Failed to deserialize CloudEvent", e);
            }
        }

        @Override
        public void close() {
            // Nothing to close
        }
    }
}
